# í˜¸ìŠ¤íŠ¸, ë„Œ ë°©ì†¡ë§Œí•´! ê´€ë¦¬ëŠ” ìš°ë¦¬ê°€ í• ê»˜!

- ğŸ€ Naver Boost camp AI tech 2nd , Team CLUE 
- ğŸ“¹ [Demonstration video]() , ğŸ–‡ï¸ [presentation slide]()

## 1.Project Abstract

âœ‹ 


## 2. ì„¤ì¹˜ ë°©ë²•

ğŸ‘‰ [ì•…í”Œ ë¶„ë¥˜ dataset ë‹¤ìš´ë¡œë“œ]()

ğŸ‘‰ [ê°ì„± ë¶„ë¥˜ dataset ë‹¤ìš´ë¡œë“œ]()
 
ğŸ‘‰ [ì‹¤ì œ ë¼ì´ë¸Œ ì»¤ë¨¸ìŠ¤ dataset ë‹¤ìš´ë¡œë“œ]()

```
# data (51.2 MB)
tar -xzf data.tar.gz
```

ğŸ‘‰ í•´ë‹¹ ë ˆí¬ ë‹¤ìš´ë¡œë“œ
```
git clone https://github.com/boostcampaitech2/final-project-level3-nlp-13.git
```

ğŸ‘‰ Poetryë¥¼ í†µí•œ íŒ¨í‚¤ì§€ ë²„ì „ ê´€ë¦¬ 

```
# curl ì„¤ì¹˜
apt-get install curl #7.58.0

# poetry ì„¤ì¹˜
curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python

# poetry íƒ­ì™„ì„± í™œì„±í™”
~/.bashrcë¥¼ ìˆ˜ì •í•˜ì—¬ poetryë¥¼ shellì—ì„œ ì‚¬ìš© í•  ìˆ˜ ìˆë„ë¡ ê°€ìƒí™˜ê²½ì— ì¶”ê°€
poetry use [ì‚¬ìš©í•˜ëŠ” ê°€ìƒí™˜ê²½ì˜ `python path` | ê°€ìƒí™˜ê²½ì´ ì‹¤í–‰ì¤‘ì´ë¼ë©´ `python`]  

# repo download í›„ ë²„ì „ ì ìš© (poetry.tomlì— ë”°ë¼ ì ìš©)
poetry install
```


## 3. ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°
### 3-1. ì €ì¥ì†Œ êµ¬ì¡°
```
â”œâ”€â”€ application
â”œâ”€â”€ crawling_data
â”œâ”€â”€ modeling
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ base_config.json
â”‚Â Â  â”œâ”€â”€ data
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ preprocessing.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ stop_words.txt
â”‚Â Â  â”œâ”€â”€ logger
â”‚Â Â  â”‚Â Â  â””â”€â”€ mylogger.py
â”‚Â Â  â”œâ”€â”€ models
â”‚Â Â  â”‚Â Â  â””â”€â”€ utill.py
â”‚Â Â  â”œâ”€â”€ train.py
â”‚Â Â  â”œâ”€â”€ train_utills
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ test.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ trainer_setting.py
â”‚Â Â  â””â”€â”€ utills
â”‚Â Â      â””â”€â”€ utill.py
â”œâ”€â”€ poetry.lock
â””â”€â”€ pyproject.toml
```
### 3-2.ë°ì´í„° êµ¬ì¡° 

ì•„ë˜ëŠ” ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹ì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

![ë°ì´í„° ë¶„í¬](./images/dataset.png)

ë°ì´í„°ì…‹ì€ í¸ì˜ì„±ì„ ìœ„í•´ Huggingface ì—ì„œ ì œê³µí•˜ëŠ” datasetsë¥¼ ì´ìš©í•˜ì—¬ pyarrow í˜•ì‹ì˜ ë°ì´í„°ë¡œ ì €ì¥ë˜ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ë°ì´í„°ì…‹ì˜ êµ¬ì„±ì…ë‹ˆë‹¤.

```python
./data/                        # ì „ì²´ ë°ì´í„°
    ./train_dataset/           # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹. train ê³¼ validation ìœ¼ë¡œ êµ¬ì„± 
    ./test_dataset/            # ì œì¶œì— ì‚¬ìš©ë  ë°ì´í„°ì…‹. validation ìœ¼ë¡œ êµ¬ì„± 
    ./wikipedia_documents.json # ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œ ì§‘í•©. retrievalì„ ìœ„í•´ ì“°ì´ëŠ” corpus.
```
ë§Œì•½ ë°ì´í„° ì¦ê°•ì„ í†µí•œ datasetì„ ì‚¬ìš©í•˜ì‹ ë‹¤ë©´, ì´ ë””ë ‰í† ë¦¬ì— ì¶”ê°€í•´ì£¼ì‹œê³ 
config ë‚´ "data_args" ë¥¼ ë³€ê²½í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.


## 4. train, evaluation , inference
### 4-1. ğŸš† train

roberta ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš°, token type idsë¥¼ ì‚¬ìš©ì•ˆí•˜ë¯€ë¡œ tokenizer ì‚¬ìš©ì‹œ ì•„ë˜ í•¨ìˆ˜ì˜ ì˜µì…˜ì„ ìˆ˜ì •í•´ì•¼í•©ë‹ˆë‹¤.
ë² ì´ìŠ¤ë¼ì¸ì€ klue/bert-baseë¡œ ì§„í–‰ë˜ë‹ˆ ì´ ë¶€ë¶„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©í•´ì£¼ì„¸ìš” ! 
tokenizerëŠ” train, validation (train.py), test(inference.py) ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ í˜¸ì¶œë˜ì–´ ì‚¬ìš©ë©ë‹ˆë‹¤.
(tokenizerì˜ return_token_type_ids=Falseë¡œ ì„¤ì •í•´ì£¼ì–´ì•¼ í•¨)
- í•™ìŠµì— í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë¥¼ configs directory ë°‘ì— .json íŒŒì¼ë¡œ ìƒì„±í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.
- í•™ìŠµëœ ëª¨ë¸ì€ tuned_models/"model_name" directoryì— bin fileì˜ í˜•íƒœë¡œ ì €ì¥ë©ë‹ˆë‹¤.
```
# train_reader.py
def prepare_train_features(examples):
        # truncationê³¼ padding(lengthê°€ ì§§ì„ë•Œë§Œ)ì„ í†µí•´ toknizationì„ ì§„í–‰í•˜ë©°, strideë¥¼ ì´ìš©í•˜ì—¬ overflowë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        # ê° exampleë“¤ì€ ì´ì „ì˜ contextì™€ ì¡°ê¸ˆì”© ê²¹ì¹˜ê²Œë©ë‹ˆë‹¤.
        tokenized_examples = tokenizer(
            ... ...
            #return_token_type_ids=False, # robertaëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° False, bertë¥¼ ì‚¬ìš©í•  ê²½ìš° Trueë¡œ í‘œê¸°í•´ì•¼í•©ë‹ˆë‹¤.
            padding="max_length" if data_args.pad_to_max_length else False,
        )
```

```
# train_reader argparser
-c, --config_file_path : train config ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” json fileì˜ ì´ë¦„
-l ,--log_file_path : train loggingì„ í•  íŒŒì¼ ì´ë¦„
-n ,--model_name : ëª¨ë¸ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬ ì´ë¦„
--do_train : Readerëª¨ë¸ train flag
--do_eval : Readerëª¨ë¸ validation flag
```

- reader í•™ìŠµ ì˜ˆì‹œ
```
python train_reader.py -c ./configs/exp1.json -l exp1.log -n experiments1 --do_train
```
    

- dense retriver í•™ìŠµ ì˜ˆì‹œ
```
python train_reader.py -c ./configs/dense_exp1.json -l dense_exp1.log -n dense_experiment1 --do_train
```

### 4-2. ğŸ“œ eval

MRC ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€(ê²€ì¦)ëŠ” (`--do_eval`) í”Œë ˆê·¸ë¥¼ ë”°ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.  ìœ„ í•™ìŠµ ì˜ˆì‹œì— ë‹¨ìˆœíˆ `--do_eval` ì„ ì¶”ê°€ë¡œ ì…ë ¥í•´ì„œ í›ˆë ¨ ë° í‰ê°€ë¥¼ ë™ì‹œì— ì§„í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

```
# mrc ëª¨ë¸ í‰ê°€ (train/validation ì‚¬ìš©)
python train_reader.py -c ./configs/exp1.json -l exp1.log -n experiments1 --do_train --do_eval
```

### 4-3. ğŸ¥• inference

retrieval ê³¼ mrc ëª¨ë¸ì˜ í•™ìŠµì´ ì™„ë£Œë˜ë©´ `inference.py` ë¥¼ ì´ìš©í•´ odqa ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

* í•™ìŠµí•œ ëª¨ë¸ì˜  test_datasetì— ëŒ€í•œ ê²°ê³¼ë¥¼ ì œì¶œí•˜ê¸° ìœ„í•´ì„  ì¶”ë¡ (`--do_predict`)ë§Œ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤. 

* í•™ìŠµí•œ ëª¨ë¸ì´ train_dataset ëŒ€í•´ì„œ ODQA ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë‚˜ì˜¤ëŠ”ì§€ ì•Œê³  ì‹¶ë‹¤ë©´ í‰ê°€(--do_eval)ë¥¼ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤.

```
# ODQA ì‹¤í–‰ (test_dataset ì‚¬ìš©)
# wandb ê°€ ë¡œê·¸ì¸ ë˜ì–´ìˆë‹¤ë©´ ìë™ìœ¼ë¡œ ê²°ê³¼ê°€ wandb ì— ì €ì¥ë©ë‹ˆë‹¤. ì•„ë‹ˆë©´ ë‹¨ìˆœíˆ ì¶œë ¥ë©ë‹ˆë‹¤
# inference argparser
-c, --config_file_path : inference config ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” json fileì˜ ì´ë¦„
-l ,--log_file_path : inference loggingì„ í•  íŒŒì¼ ì´ë¦„
-n ,--inference_name : inference ê²°ê³¼ê°€ ì €ì¥ë  ë””ë ‰í† ë¦¬ ì´ë¦„
-m , --model_name_or_path : inferenceì— ì‚¬ìš©í•  ëª¨ë¸ ë””ë ‰í† ë¦¬ì˜ ì´ë¦„
```

```
python inference.py -c infer1.json -l infer1.log --n infer1_result -m ./tuned_models/train_dataset/ --do_predict
```

### 4-4. How to submit
`inference.py` íŒŒì¼ì„ ìœ„ ì˜ˆì‹œì²˜ëŸ¼ `--do_predict` ìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ `--inference_name` ìœ„ì¹˜ì— `predictions.json` ì´ë¼ëŠ” íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ì„ ì œì¶œí•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.

### 4-5. MRC ëª¨ë¸ í•™ìŠµ ê²°ê³¼
ë‹¤ìŒì€ MRC ëª¨ë¸ì˜ public & private datsetì— ëŒ€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

- Public 19íŒ€ ì¤‘ 9ë“± ğŸ¥ˆ
![Public ğŸ¥ˆ](./images/public.png)

- Private 19íŒ€ ì¤‘ 7ë“± ğŸ¥ˆ
![Private ğŸ¥ˆ](./images/private.png)


## 5. Things to know

1. `inference.py` ì—ì„œ TF-IDF scoreì˜ ê²½ìš° sparse embedding ì„ í›ˆë ¨í•˜ê³  ì €ì¥í•˜ëŠ” ê³¼ì •ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ì§€ ì•Šì•„ ë”°ë¡œ argument ì˜ default ê°€ Trueë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹¤í–‰ í›„ sparse_embedding.bin ê³¼ tfidfv.bin ì´ ì €ì¥ì´ ë©ë‹ˆë‹¤. **ë§Œì•½ sparse retrieval ê´€ë ¨ ì½”ë“œë¥¼ ìˆ˜ì •í•œë‹¤ë©´, ê¼­ ë‘ íŒŒì¼ì„ ì§€ìš°ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”!** ì•ˆê·¸ëŸ¬ë©´ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì´ load ë©ë‹ˆë‹¤.
2. ëª¨ë¸ì˜ ê²½ìš° `--overwrite_cache` ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ ê°™ì€ í´ë”ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 

3. ./predictions/ í´ë” ë˜í•œ `--overwrite_output_dir` ì„ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ ê°™ì€ í´ë”ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.


## 6. License

This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />
